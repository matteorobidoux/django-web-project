{
  "posts": [
    {
        "id": 1,
        "name": "API Documentation",
        "owner": 7,
        "type": "Theoretical",
        "field": "Computer Science",
        "keyword_list": "ResearchGate",
        "content": "Documenting a REST API is important for its successful adoption. APIs expose data and services that consumers want to use. An API should be designed with an interface that the consumer can understand. API documentation is key to the app developers comprehending the API. The documentation should help the developer to learn about the API functionality and enable them to start using it easily. This chapter looks at the aspects of documenting an API and some of the tools and technologies available for API documentation, including RAML, Swagger, API Blueprint, and others.",
        "url": "https://www.researchgate.net/publication/315468327_API_Documentation",
        "status": "Completed"
    },
    {
        "id": 2,
        "name": "Big Data and Big Data Analytics",
        "owner": 7,
        "type": "Theoretical",
        "field": "Computer Science",
        "keyword_list": "ResearchGate",
        "content": "Big data now is a common term. However, the evolution of big data comes from twofold. The creation of the computer in the 1940s gradually provides tools for human beings to collect massive data, while the term “big data” becomes a popular slogan to represent the collection, processing, and analysis of various data [1]. The data has been exponentially growing for the last 70 decades. EMC2 [2] estimated that the world generated 1.8 zettabytes of data (1.8 multiple 21 zeros) by 2011. In fact, this figure has grown to 44 zettabytes, about 24 times in 2020. Big Data Analytics has arisen as the technical means dealing with both theory and application of big data. This chapter elaborates on the understanding of big data and its analytics. Section 1.1 briefly describes big data evolution and challenges. Section 1.2 is about big data’s current status, including its development in the world as well as in China. Section 1.3 explores big data analysis and data science problems.",
        "url": "https://www.researchgate.net/publication/357803871_Big_Data_and_Big_Data_Analytics",
        "status": "Completed"
    },
    {
        "id": 3,
        "name": "Denial of Service Attack on Bluetooth Low Energy",
        "owner": 7,
        "type": "Theoretical",
        "field": "Computer Science",
        "keyword_list": "Security,Bluetooth",
        "content": "Bluetooth Low Energy is a promising technology for wireless \ncommunication.  The  main  benefits  are  that  it  is  energy \nefficient and is slowly becoming ubiquitous. We can expect \nthat  the  technology  will  be  used  in  many  demanding \napplications. \nThis raises the question whether Bluetooth Low Energy  is \nsuitable for products and services that require high resilience, \nrobustness and availability. \nIn  this  paper  we  focus  on  the  availability  aspects  in  the \nconnection setup of Bluetooth Low Energy. We explore an \nattack path that allows us to do a denial of service attack on \nthe  connection  setup  mechanism.  We  refine  the  attack \nscenario  and  implement  an  exploit  using  the  Project \nUbertooth,  an  open  source  platform  for  Bluetooth \nexperimentation. We then characterize the attack vector using \nthe Common Criteria attack evaluation methodology. \nOur result indicates that it is possible to successfully mount a \ndenial of service attack that blocks the connection setup  on \nBluetooth  Low  Energy  using  standard  off-the-shelf \ncomponents. The consequence of this exploit helps us bring \nawareness  that Bluetooth  Low  Energy  may  not guarantee \navailability when an attacker has the motivation and vicinity \naccess. ",
        "url": "https://www.researchgate.net/publication/317063884_Denial_of_Service_Attack_on_Bluetooth_Low_Energy",
        "status": "Completed"
    },
    {
        "id": 4,
        "name": "Research on Detecting Windows Vulnerabilities Based on Security Patch Comparison",
        "owner": 7,
        "type": "Theoretical",
        "field": "Computer Science",
        "keyword_list": "Security,Vulnerability",
        "content": "By analyzing the binary executable files comparing technique, this paper presents a method to detect vulnerabilities in Windows system based on security patch comparison. The technology is mostly used for detecting vulnerabilities which are patched by Microsoft but there is no clear location and detailed information of the vulnerabilities. Finally, the result of detecting MS15-034 vulnerability experiment demonstrates the effectiveness of the technique.",
        "url": "https://www.researchgate.net/publication/311530915_Research_on_Detecting_Windows_Vulnerabilities_Based_on_Security_Patch_Comparison",
        "status": "Completed"
    },
    {
        "id": 5,
        "name": "The Sense of Logging in the Linux Kernel",
        "owner": 7,
        "type": "Empirical",
        "field": "Software Engineering",
        "keyword_list": "Software Engineering,Linux",
        "content": "Logging plays a crucial role in software engineering because it is key to perform various tasks including debugging, performance analysis, and detection of anomalies. Despite the importance of log data, the practice of logging still suffers from the lack of common guidelines and best practices. Recent studies investigated logging in C/C++ and Java open-source systems. In this paper, we complement these studies by conducting the first empirical study on logging practices in the Linux kernel , one of the most elaborate open-source development projects in the computer industry. We analyze 22 Linux releases with a focus on three main aspects: the pervasiveness of logging in Linux, the types of changes made to logging statements, and the rationale behind these changes. Our findings show that logging code accounts for 3.73% of the total source code in the Linux kernel, distributed across 72.36% of Linux files. We also found that the distribution of logging statements across Linux subsystems and their components vary significantly with no apparent reasons, suggesting that developers use different criteria when logging. In addition, we observed a slow decrease in the use of logging-reduction of 9.27% between versions v4.3 and v5.3. The majority of changes in logging code are made to fix language issues, modify log levels, and upgrade logging code to use new logging libraries, with the overall goal of improving the precision and consistency of the log output. Many recommendations are derived from our findings such as the use of static analysis tools to detect log-related issues, the adoption of common writing styles to improve the quality of log messages, the development of conventions to guide developers when selecting log levels, the establishment of review sessions to review logging code, and so on. Our recommendations can serve as a basis for developing logging guidelines as well as better logging processes, tools, and techniques.",
        "url": "https://www.researchgate.net/publication/360081286_The_Sense_of_Logging_in_the_Linux_Kernel",
        "status": "Completed"
    },
    {
        "id": 6,
        "name": "Clones in deep learning code: what, where, and why?",
        "owner": 7,
        "type": "Empirical",
        "field": "Software Engineering",
        "keyword_list": "Code Clones,Deep Learning,Clone Taxonomy",
        "content": "Deep Learning applications are becoming increasingly popular world-\nwide. Developers of deep learning systems like in every other context of soft-\nware development strive to write more eﬃcient code in terms of performance,\ncomplexity, and maintenance. The continuous evolution of deep learning sys-\ntems imposing tighter development timelines and their increasing complexity\nmay result in bad design decisions by the developers. Besides, due to the use\nof common frameworks and repetitive implementation of similar tasks, deep\nlearning developers are likely to use the copy-paste practice leading to clones\nin deep learning code. Code clone is considered to be a bad software devel-\nopment practice since developers can inadvertently fail to properly propagate\nchanges to all clones fragments during a maintenance activity. However, to\nthe best of our knowledge, no study has investigated code cloning practices\nin deep learning development. The majority of research on deep learning sys-\ntems mostly focusing on improving the dependability of the models. Given\nthe negative impacts of clones on software quality reported in the studies on\ntraditional systems and the inherent complexity of maintaining deep learning\nsystems (e.g., bug ﬁxing), it is very important to understand the characteris-\ntics and potential impacts of code clones on deep learning systems. This paper\nexamines the frequency, distribution, and impacts of code clones and the code\ncloning practices in deep learning systems. To accomplish this, we use the\nNiCad clone detection tool to detect clones from 59 Python, 14 C#, and 6\nJava based deep learning systems and an equal number of traditional software\nsystems. We then analyze the comparative frequency and distribution of code\nclones in deep learning systems and the traditional ones. Further, we study\nthe distribution of the detected code clones by applying a location based tax-\nHadhemi Jebnoun ·Md Saidur Rahman ·Foutse Khomh ·Biruk Asmare Muse\nE-mail: {hadhemi.jebnoun,saidur.rahman,foutse.khomh, biruk-asmare.muse}@polymtl.ca\nDGIGL, Polytechnique Montreal, QC, Canada,\n2 Jebnoun et al.\nonomy. In addition, we study the correlation between bugs and code clones to\nassess the impacts of clones on the quality of the studied systems. Finally, we\nintroduce a code clone taxonomy related to deep learning programs based on\n6 DL software systems (from 59 DL systems) and identify the deep learning\nsystem development phases in which cloning has the highest risk of faults. Our\nresults show that code cloning is a frequent practice in deep learning systems\nand that deep learning developers often clone code from ﬁles contain in dis-\ntant repositories in the system. In addition, we found that code cloning occurs\nmore frequently during DL model construction, model training, and data pre-\nprocessing. And that hyperparameters setting is the phase of deep learning\nmodel construction during which cloning is the riskiest, since it often leads to\nfaults",
        "url": "https://www.researchgate.net/publication/359830415_Clones_in_deep_learning_code_what_where_and_why",
        "status": "Completed"
    },
    {
        "id": 7,
        "name": "Multi-criteria Optimization Approach for the Deployment",
        "owner": 1,
        "type": "Empirical",
        "field": "Networking",
        "keyword_list": "Wireless Mesh Network,Planning problem,Multi-objective optimization,Meta-heuristic search algorithm",
        "content": "The few studies carried out so far on planning Wireless Mesh Networks (WMNs) tend all to be mono-objective optimization models. We propose a different approach to address the planning of WMN problem that reflects as much as possible the real-life problem. Basically, an optimal (or rather a good and realistic) planning solution has to be simultaneously cheap (minimizing the deployment cost) and efficient (maximizing the throughput). To achieve this, we devise a novel generic multi-objective optimization model where the two objectives of network cost deployment and network throughput are simultaneously optimized under obvious network constraints. We then derive two instance models differing mainly in how the second objective is defined: maximizing the culmination of the flows over the entire network or minimizing the aggregation of network interferences. Obviously, a new network metric is proposed to handle this task. A comparative experimental study with different key-parameter settings on the two instance models is conducted to help network planner decide which planning optimization model to choose given their specific requirements and/or scenarios.",
        "url": "https://www.researchgate.net/publication/228997248_Multi-criteria_optimization_approach_for_the_deployment_planning_problem_of_multi-hop_wireless_networks",
        "status": "Completed"
    },
    {
        "id": 8,
        "name": "Detecting Distributed Denial of Service attacks using Recurrent Neural Network",
        "owner": 7,
        "type": "Empirical",
        "field": "Neural Networks",
        "keyword_list": "Distributed  Denial  of  Service  (DDoS)  Attacks, Recurrent  Neural  Network  (RNN),Knowledge  Discovery  Dataset  (KDD), Artificial Neural Network (ANN)",
        "content": "As  the  internet  grows  and  diversity,  attackers  use  various  attacks  to  crash  the  servers  and  to  stop  specific \nsites.  Multiple  computers  and  multiple  Internet  connections  are  targeted  by  using  distributed  denial  of  service \n(DDoS)  attacks.  The  aim  of  this  paper  is  to  identify  the  best  algorithm  among  the  selected  algorithms  (i.e.,  gradient \ndescent  with  momentum  algorithm,  scaled  conjugate  gradient,  and  variable  learning  rate  gradient  descent  algorithm.  \nIn  this  study,  the  recurrent  neural  network  was  trained  to  check  the  accuracy  and  detection  of  DDoS  attacks.  The \nintention  of  this  training  was  to  allow  the  system  to  learn  and  classify  the  input  traffic  into  the  category.  The \nproposed  system's  training  was  composed  of  three  separate  algorithms  utilizing  recurrent  neural  networks.  The \nMATLAB  2018a  simulator  was  used  for  training  purpose.  Moreover,  clean  the  Knowledge  Discovery  Dataset \n(KDD)  during  design  and  include  the  values  of  protocols,  attacks,  and  flags.  The  neural  network  model  was \nsubsequently  developed,  and  the  KDD  was  trained  using  Artificial  Neural  Network  (ANN).  The  results  of  DDoS \nattacks’  detection  were  analyzed  using  MATLAB “ANN”  toolbox.  The  success  rate  of  the  variable  learning  rate \ngradient  descent  algorithm  was  99.9%  accuracy  and  the  short  timing  was  2  minutes  and  29  seconds.  The  variable \nlearning  rate  gradient  descent  algorithm  gives  better  results  than  gradient  descent  with  momentum  and  scaled \nconjugate  gradient  algorithms.    In  the  state  of  the  art,  different  algorithms  have  been  trained  in  different  neural \nnetworks  and  different  KDD  datasets  by  using  selective  DDoS  attacks  but  in  this  research  recurrent  neural  network \nwas  used  for  three  different  algorithms.  In  this  research  we  have  used  a  total  22  attacks  for  detection  of  DDoS \nattacks’ accuracy. ",
        "url": "https://www.researchgate.net/publication/359300444_Detecting_Distributed_Denial_of_Service_attacks_using_Recurrent_Neural_Network",
        "status": "Completed"
    },
    {
        "id": 9,
        "name": "Fish classification using extraction of appropriate feature set",
        "owner": 7,
        "type": "Empirical",
        "field": "Electrical and Computer Engineering",
        "keyword_list": "Feature selection,image retrieval,particle swarm optimization",
        "content": "The field of wild fish classification faces many challenges such as the amount of training data, pose variation and uncontrolled environmental settings. This research work introduces a hybrid genetic algorithm (GA) that integrates the simulated annealing (SA) algorithm with a back-propagation algorithm (GSB classifier) to make the classification process. The algorithm is based on determining the suitable set of extracted features using color signature and color texture features as well as shape features. Four main classes of fish images have been classified, namely, food, garden, poison, and predatory. The proposed GSB classifier has been tested using 24 fish families with different species in each. Compared to the back-propagation (BP) algorithm, the proposed classifier has achieved a rate of 87.7% while the elder rate is 82.9%.",
        "url": "https://www.researchgate.net/publication/359482583_Fish_classification_using_extraction_of_appropriate_feature_set",
        "status": "Completed"
    },
    {
        "id": 10,
        "name": "Connecting reservoir computing with statistical forecasting and deep neural networks",
        "owner": 7,
        "type": "Theoretical",
        "field": "Nature Communications",
        "keyword_list": "Resevoir Computing,Physiology,Artificial Neural Networks,Biosignals,Machine Learning,Biomedical Signal Processing",
        "content": "Standfirst Among the existing machine learning frameworks, reservoir computing demonstrates fast and low-cost training, and its suitability for implementation in various physical systems. This Comment reports on how aspects of reservoir computing can be applied to classical forecasting methods to accelerate the learning process, and highlights a new approach that makes the hardware implementation of traditional machine learning algorithms practicable in electronic and photonic systems.",
        "url": "https://www.researchgate.net/publication/357756177_Connecting_reservoir_computing_with_statistical_forecasting_and_deep_neural_networks",
        "status": "Completed"
    },
    {
        "id": 11,
        "name": "Effect of service differentiation on QoS in IEEE 802.11e enhanced distributed channel access",
        "owner": 7,
        "type": "Theoretical",
        "field": "Engineering",
        "keyword_list": "EDCA protocol,Medium access control,AIFS,QoS,Contention window,MATLAB",
        "content": "The enhanced distributed channel access (EDCA) protocol is a supplement to IEEE 802.11 medium access control (MAC), ratified by IEEE 802.11e task group to support quality of service (QoS) requirements of both data and real-time applications. Previous research show that it supports priority scheme for multimedia traffic but strict QoS is not guaranteed. This can be attributed to inappropriate tuning of the medium access parameters. Thus, an in-depth analysis of the EDCA protocol and ways of tuning medium access parameters to improve QoS requirements for multimedia traffic is presented in this work. An EDCA model was developed and simulated using MATLAB to assess the effect of differentiating contention window (CW) and arbitration inter-frame space (AIFS) of different traffic on QoS parameters. The optimal performance, delay, and maximum sustainable throughput for each traffic type were computed under saturation load. Insight shows that traffic with higher priority values acquired most of the available channels and starved traffic with lower priority values. The AIFS has more influence on the QoS of EDCA protocol. It was also observed that small CW values generate higher packet drops and collision rate probability. Thus, EDCA protocol provides mechanism for service differentiation which strongly depends on channel access parameters: CW sizes and AIFS.",
        "url": "https://www.researchgate.net/publication/357598795_Effect_of_service_differentiation_on_QoS_in_IEEE_80211e_enhanced_distributed_channel_access_a_simulation_approach",
        "status": "Completed"
    },
    {
        "id": 12,
        "name": "A Mathematical Model for the Dynamics of Rhinopharyngitis in a Population",
        "owner": 7,
        "type": "Theoretical",
        "field": "Bioinformatics",
        "keyword_list": "Basic Reproduction Number,Steady States,Local and Global Stability,Common Cold; Simulation,Rhinopharyngitis",
        "content": "This paper considered a deterministic SIR model to investigate the transmission dynamics of common cold within a population. This study was based on the assumption that every individual in the population is susceptible to the common cold. The steady states of the model were calculated and the local and global asymptotic stability analyzed. The basic reproduction number R 0 was determined. The disease becomes endemic whenever R 0 >1 and dies out whenever R 0 <1. Simulations of the model were performed. It was found that the transmission rate is most sensitive to the disease; any attempt to reduce the transmission rate is marked by a reduction in the number of infectious individuals.",
        "url": "https://www.researchgate.net/publication/356535776_Journal_of_Applied_Bioinformatics_Computational_Biology_A_Mathematical_Model_for_the_Dynamics_of_Rhinopharyngitis_in_a_Population",
        "status": "Completed"
    },
    {
        "id": 13,
        "name": "Genetic variations influence brain changes in patients with attention-deficit hyperactivity disorder",
        "owner": 7,
        "type": "Theoretical",
        "field": "Translational Psychiatry",
        "keyword_list": "ResearchGate",
        "content": "Attention-deficit hyperactivity disorder (ADHD) is a neurological and neurodevelopmental childhood-onset disorder characterized by a persistent pattern of inattentiveness, impulsiveness, restlessness, and hyperactivity. These symptoms may continue in 55–66% of cases from childhood into adulthood. Even though the precise etiology of ADHD is not fully understood, it is considered as a multifactorial and heterogeneous disorder with several contributing factors such as heritability, auxiliary to neurodevelopmental issues, severe brain injuries, neuroinflammation, consanguineous marriages, premature birth, and exposure to environmental toxins. Neuroimaging and neurodevelopmental assessments may help to explore the possible role of genetic variations on ADHD neuropsychobiology. Multiple genetic studies have observed a strong genetic association with various aspects of neuropsychobiological functions, including neural abnormalities and delayed neurodevelopment in ADHD. The advancement in neuroimaging and molecular genomics offers the opportunity to analyze the impact of genetic variations alongside its dysregulated pathways on structural and functional derived brain imaging phenotypes in various neurological and psychiatric disorders, including ADHD. Recently, neuroimaging genomic studies observed a significant association of brain imaging phenotypes with genetic susceptibility in ADHD. Integrating the neuroimaging-derived phenotypes with genomics deciphers various neurobiological pathways that can be leveraged for the development of novel clinical biomarkers, new treatment modalities as well as therapeutic interventions for ADHD patients. In this review, we discuss the neurobiology of ADHD with particular emphasis on structural and functional changes in the ADHD brain and their interactions with complex genomic variations utilizing imaging genetics methodologies. We also highlight the genetic variants supposedly allied with the development of ADHD and how these, in turn, may affect the brain circuit function and related behaviors. In addition to reviewing imaging genetic studies, we also examine the need for complementary approaches at various levels of biological complexity and emphasize the importance of combining and integrating results to explore biological pathways involved in ADHD disorder. These approaches include animal models, computational biology, bioinformatics analyses, and multimodal imaging genetics studies.",
        "url": "https://www.researchgate.net/publication/352160301_Genetic_variations_influence_brain_changes_in_patients_with_attention-deficit_hyperactivity_disorder",
        "status": "Completed"
    },
    {
        "id": 14,
        "name": "Protein-Based Immunome Wide Association Studies (PIWAS)...",
        "owner": 7,
        "type": "Theoretical",
        "field": "Immunology",
        "keyword_list": "computational immunology,antigen,immunome,bioinformatics & computational biology,immunology&inﬂammation",
        "content": "Identification of the antigens associated with antibodies is vital to understanding immune responses in the context of infection, autoimmunity, and cancer. Discovering antigens at a proteome scale could enable broader identification of antigens that are responsible for generating an immune response or driving a disease state. Although targeted tests for known antigens can be straightforward, discovering antigens at a proteome scale using protein and peptide arrays is time consuming and expensive. We leverage Serum Epitope Repertoire Analysis (SERA), an assay based on a random bacterial display peptide library coupled with next generation sequencing (NGS), to power the development of Protein-based Immunome Wide Association Study (PIWAS). PIWAS uses proteome-based signals to discover candidate antibody-antigen epitopes that are significantly elevated in a subset of cases compared to controls. After demonstrating statistical power relative to the magnitude and prevalence of effect in synthetic data, we apply PIWAS to systemic lupus erythematosus (SLE, n=31) and observe known autoantigens, Smith and Ribosomal protein P, within the 22 highest scoring candidate protein antigens across the entire human proteome. We validate the magnitude and location of the SLE specific signal against the Smith family of proteins using a cohort of patients who are positive by predicate anti-Sm tests. To test the generalizability of the method in an additional autoimmune disease, we identified and validated autoantigenic signals to SSB, CENPA, and keratin proteins in a cohort of individuals with Sjogren’s syndrome (n=91). Collectively, these results suggest that PIWAS provides a powerful new tool to discover disease-associated serological antigens within any known proteome.",
        "url": "https://www.researchgate.net/publication/351125370_Protein-Based_Immunome_Wide_Association_Studies_PIWAS_for_the_Discovery_of_Significant_Disease-Associated_Antigens",
        "status": "Completed"
    },
    {
        "id": 15,
        "name": "A novel big data mining framework for reconstructing large-scale daily...",
        "owner": 7,
        "type": "Theoretical",
        "field": "Data Analysis",
        "keyword_list": "MAIAC AOD,large-scale reconstruction,variation information,iteration strategy,China",
        "content": "Satellite-based  aerosol  optical depth  (AOD) retrieval  products are  essential in  air  pollution and \nclimate change research. Unfortunately, cloud contaminations and unfavorable surface conditions \nresult in a considerable proportion of missing  AOD data. Numerous studies  have been conducted \nto  reconstruct  large-scale  AOD  data  gaps  by  utilizing  adjacent  spatiotemporal  information  or \nmodeling  AOD  data  via  various  external  geographical  data.  However,  the  erratic  variation  of \nAOD and the inconvenience of external data weaken the accuracy and e\uE02Eciency of reconstruction. \nTo  address  these  issues,  a  novel  big  data  based  iterative  variation  mining  framework  (IVMF), \nutilizing  multi-spatiotemporal information  on  AOD variations,  is proposed  to reconstruct  large- \nscale AOD data over China from 2000 to 2020. Simulated and real-data experiments are carried out \nto validate the e\uE035ectiveness and robustness of the IVMF. Results show  that the spatial patterns of \nthe reconstructed AOD are consistent with those of the original AOD in the simulated experiments. \nThe \uE037nal reconstructed AOD data strongly correlate with in-situ AOD measurements in  the real- \ndata  experiments  (correlation  coe\uE02Ecient  of  0.91).  After  reconstruction,  the  average  daily  AOD \ncoverage increases from 30.42% to  96.69% (a 218%  increase). Besides,  results reveal  that central \nChina  exhibits  severe AOD  levels, while  northwest China  presents  low AOD  levels. Overall,  the \nproposed IVMF can largely resolve the missing AOD data problem with outstanding accuracy and \ne\uE02Eciency,  and  has  great  potential  to  be  generalized  to  other  regions  and  remote sensing \nproducts.",
        "url": "https://www.researchgate.net/publication/359382647_A_novel_big_data_mining_framework_for_reconstructing_large-scale_daily_MAIAC_AOD_data_across_China_from_2000_to_2020",
        "status": "Completed"
    },
    {
        "id": 16,
        "name": "Protocol for inducible piggyBac transposon system for efficient...",
        "owner": 7,
        "type": "Theoretical",
        "field": "Molecular Biology",
        "keyword_list": "Medical science,ResearchGate,STAR Protocols",
        "content": "In human pluripotent stem cells (hPSCs), traditional approaches for gene overexpression have low efficiency and are often laborious. Here, we provide a relatively simple protocol for gene overexpression with the Dox-inducible PiggyBac transposon system. We detail the steps for overexpression of FLI1 and/or YAP in H1 embryonic stem cells (H1 ESCs) as an example. Our protocol can be applied to any gene of interest in a variety of hPSCs. For complete details on the use and execution of this protocol, please refer to Quan et al. (2021).",
        "url": "https://www.researchgate.net/publication/359937480_Protocol_for_inducible_piggyBac_transposon_system_for_efficient_gene_overexpression_in_human_pluripotent_stem_cells",
        "status": "Completed"
    },
    {
        "id": 17,
        "name": "An open quantum systems approach to proton tunnelling in DNA",
        "owner": 7,
        "type": "Theoretical",
        "field": "Physics",
        "keyword_list": "DNA,ResearchGate,Proton tunneling,Open quantum systems,Molecular Biology",
        "content": "One of the most important topics in molecular biology is the genetic stability of DNA. One threat to this stability is proton transfer along the hydrogen bonds of DNA that could lead to tautomerisation, hence creating point mutations. We present a theoretical analysis of the hydrogen bonds between the Guanine-Cytosine (G-C) nucleotide, which includes an accurate model of the structure of the base pairs, the quantum dynamics of the hydrogen bond proton, and the influence of the decoherent and dissipative cellular environment. We determine that the quantum tunnelling contribution to the proton transfer rate is several orders of magnitude larger than the classical over-the-barrier hopping. Due to the significance of the quantum tunnelling even at biological temperatures, we find that the canonical and tautomeric forms of G-C inter-convert over timescales far shorter than biological ones and hence thermal equilibrium is rapidly reached. Furthermore, we find a large tautomeric occupation probability of 1.73 × 10−4, suggesting that such proton transfer may well play a far more important role in DNA mutation than has hitherto been suggested. Our results could have far-reaching consequences for current models of genetic mutations. The genetic stability of DNA suffers from proton transfer along the hydrogen bonds that can lead to tautomerisation, creating mutations. The authors theoretically examine the tautomerisation of the GuanineCytosine (G-C) nucleotide base-pair using an open quantum systems approach, finding that the contribution of quantum tunnelling to the reaction rate outweighs classical barrier-hopping.",
        "url": "https://www.researchgate.net/publication/360387921_An_open_quantum_systems_approach_to_proton_tunnelling_in_DNA",
        "status": "Completed"
    },
    {
        "id": 18,
        "name": "Time Sensitive Networking Protocol Implementation for Linux End Equipment",
        "owner": 7,
        "type": "Theoretical",
        "field": "Networking",
        "keyword_list": "Linux,ResearchGate,Time Sensitive Networking,IEEE",
        "content": "By bringing industrial-grade robustness and reliability to Ethernet, Time Sensitive Networking (TSN) offers an IEEE standard communication technology that enables interoperability between standard-conformant industrial devices from any vendor. It also eliminates the need for physical separation of critical and non-critical communication networks, which allows a direct exchange of data between operation centers and companies, a concept at the heart of the Industrial Internet of Things (IIoT). This article describes creating an end-to-end TSN network using specialized PCI Express (PCIe) cards and two final Linux endpoints. For this purpose, the two primary standards of TSN, IEEE 802.1AS (regarding clock synchronization), and IEEE 802.1Qbv (regarding time scheduled traffic) have been implemented in Linux equipment as well as a configuration and monitoring system.",
        "url": "https://www.researchgate.net/publication/360160668_Time_Sensitive_Networking_Protocol_Implementation_for_Linux_End_Equipment",
        "status": "Completed"
    },
    {
        "id": 19,
        "name": "Software system comparison with semantic source code embeddings",
        "owner": 7,
        "type": "Theoretical",
        "field": "Software Engineering",
        "keyword_list": "Source code embeddings,Software comparison,Code similarity,code2vec,Machine learning",
        "content": "This paper presents a novel approach for comparing software systems by calculating the robust Hausdorff distance between semantic source code embeddings of individual software components, i.e., methods. The proposed approach represents each software as a set of vectors, where every vector is a semantic source code embedding of a particular method. The code embeddings are constructed from abstract syntax trees of the methods with the help of attention-based neural network models that capture the semantics of the methods. Previous research has shown that comparing semantic source code embeddings can reveal semantic relationships between the two methods. We utilize this characteristic to estimate the semantic similarity between the two software systems by computing the robust Hausdorff distance. In the experiment, a pre-trained code2vec neural network model is used to create the source code vector representations of several open-source Java-based libraries. Several variations of the robust Hausdorff distance are evaluated. The results show that the proposed approach can effectively estimate the semantic similarity, reflecting the software library’s scopes, software evolution, and individual parts (e.g., packages) of those libraries.",
        "url": "https://www.researchgate.net/publication/359308944_Software_system_comparison_with_semantic_source_code_embeddings",
        "status": "Completed"
    },
    {
        "id": 20,
        "name": "A hybrid nature-inspired optimizer for wireless mesh networks design",
        "owner": 1,
        "type": "Theoretical",
        "field": "Computer Communications",
        "keyword_list": "ResearchGate,Wireless Mesh Networks,Networking",
        "content": "Existing approaches for optimal planning of wireless mesh networks (WMNs) deployment revolves around the deployment cost as the pivotal concept to optimize. In this paper, we adopt a new approach to optimize the planning of WMNs that guarantees an acceptable level of network performance prior to its deployment. It is a simultaneous optimization process of network deployment cost and network throughput objectives while taking into account all the parameters that have a significant impact on the network efficiency. We propose three multi-objective models for WMN planning problem, namely Load-Balanced Model, Interference Model, and Flow-Capacity Model. We devise an evolutionary swarm-based algorithm that is a hybrid combination of multi-objective Particle Swarm Optimization (MOPSO) and Genetic Algorithms (GAs) to solve the three models. We use realistic network sizes (up to 100 mesh nodes) to perform a thorough comparative experimental study on these three instance models with different key-parameter settings. Finally, we use the network simulator OMNET++ to evaluate the three models in terms of the actual performance (network throughput). The results presented in this paper show that Load-Balanced Model totally supersedes the Flow-Capacity Model and performs better than the Interference Model.",
        "url": "https://www.researchgate.net/publication/256942110_A_hybrid_nature-inspired_optimizer_for_wireless_mesh_networks_design",
        "status": "Completed"
    }
  ]
}